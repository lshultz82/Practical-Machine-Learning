Title Practical Machine Learning Course Project
========================================================
#Loading and PreProcessing the Data
Data were obtained under the auspices of a Creative Common License from the GroupWare@LES Human Activity Recognition Lab.  The purpose of the study was to use an on-body sensing apparatus to create a method that would allow the user to receive accurate and appropriate feedback not just on the quantitative aspects of their exerice performance, but also specifically tailored feed back on their qualitative execution.  The experiment included six healthy individuals who were asked to perform one set of 10 repetitions of unilateral dumbbell bicep curls in five conditions: one with the correct techinque and 4 others with various forms of improper techinque.  Data was collected from the onbody sensor in order to attempt to create a predictive algorithm via the aforementioned device containing an accelerometer which would allow the model to correctly interpret when the wearer is using proper vs. improper technique.

First we load the appropriate data packages and create a working directory, then read in the unzipped data obtained from the HAR Lab, in .csv format.
```{r setoptions,echo=TRUE,cache=TRUE}

```
```{r}
temp <- tempfile()
download.file("https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv", temp,method="curl")
data <- read.csv(temp)
library(caret)
```
We then do a cursory series of data inspection to determine the integrity of the database.
```{r}
dim(data)
str(data)

```
We find 19622 observations with 160 variables. Column names seem appropriate.  This number of variables is particularly cumbersome, and a more refined database can be created from which to build a predicitive model.  From a cursory glance, it appears that some variables have either a significant number of values that are NA or completely neglected.  Given the array of variables from which to build the model, it will be expediant to eliminate any which do not contact a complete record across all observations.

```{r}
data[data == ""]<-NA
data_mod<-data[,which(as.numeric(colSums(is.na(data)))==0)]
summary(data_mod)
```
This brings the database down to 60 variables.  Next a cursory examination of the variables indicates there are a number tagged to metadata rather than explanatory variables.  These are eliminated for the predictive model, taking the potential variables to 53.

```{r}
data_mod_clean<-data_mod[,-c(1:7)]
```

This database will then be divided into a training and validation set (it was not done prior to optimize computing time, though this would have been preferable for validity). Prior to analysis factor variables must be converted to numeric.
```{r}
inTrain<-createDataPartition(y=data_mod_clean$classe,p=0.7,list=FALSE)
training<-data_mod_clean[inTrain,]
validating<-data_mod_clean[-inTrain,]
dim(training)
dim(validating)
```
To further narrow down variables to use in the predictive model, principal component analysis is applied, with the ultimate predictor value of interest(classe) removed.  
```{r}

preProc<-preProcess(training[,-53],method="pca")
```

26 components were used to capture 95% of the variance.  A model is then fit using the method random forest with single cross-validation (for runtime efficiency).

```{r}
trainPC<-predict(preProc,training[,-53])
modelFit<-train(training$classe~.,method="rf",data=trainPC,trControl=trainControl(method="cv"))
modelFit$finalModel
```
Using random forest with cross validation (chosen for time and working power constraints) after delimiting the variables using PCA, an algorithm results that has an OOB estimate of error rate of 2.65%.  The disadvantage of this approach was a very lengthy runtime.  Testing the algorithm against the validation set drawn from the original training data is completed.

```{r}
validatePC<-predict(preProc,validating[,-53])
confusionMatrix(validating$classe,predict(modelFit,validatePC))
```
This shows a highly accurate model with an accuracy rate of 0.978, CI (0.9742,0.9818), and a p-value of 2.2e-16 with a kappa of .9723.  The confusion matrix shows a few misses in each class (between 3 and 14), but the overall accuracy remains substantial in each. Positive and negative predictive values are between .985 and .998 across the classes, leading to remarkable confidence in the ability of this model to accurately delinate among the classes.

A second model was created for comparison.  Instead of PCA, highly correlated variables were removed by hand, leaving 42 predictors.

```{r}
correlated<-findCorrelation(cor(training[, 1:52]), cutoff=0.8)
training_mod<-training[,-correlated]
modelFit2<-train(training_mod$classe~.,method="rf",data=training_mod[-43],trControl=trainControl(method="cv"))
modelFit2$finalModel
validating_mod<-validating[,-correlated]
confusionMatrix(validating$classe,predict(modelFit2,validating_mod[-43]))

```
This alternative model gives an OOB error rate of 0.8%.  The validation data set is predicted with an accuracy of .9941, kappa of .9925.  One advantage of this model is that it allows us to find the most important variables for prediction.

```{r}
plot(varImp(modelFit2,scale=FALSE))
```

This allows us to see perhaps for future analysis or manufacturing specification a few particular variables have an overriding amount of importance.

The testing set is loading, and modified as per the training set (for each model).

```{r}
temp2 <- tempfile()
download.file("https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv", temp2,method="curl")
data2 <- read.csv(temp2)
data2[data2 == ""]<-NA
data2_mod<-data2[,which(as.numeric(colSums(is.na(data2)))==0)]
summary(data2_mod)
data2_mod_clean<-data2_mod[,-c(1:7)]
```
The prediction is then performed.
```{r}
testingPC<-predict(preProc,data2_mod_clean[,-53])
pred_mod1<-predict(modelFit,testingPC)
```

```{r}
data2_mod_clean_hand<-data2_mod_clean[,-correlated]
pred_mod2<- predict(modelFit2,data2_mod_clean_hand[,-43])
```
```{r}
pred_mod1;pred_mod2
```
Both models result in remarkably similar predictions, with only one discrepancy.  We will select the second model for our final analysis, as the out of sample error rate is predicted to be just slightly lower.
To create the final output files:
```{r}
pml_write_files = function(x){
  n = length(x)
  for(i in 1:n){
    filename = paste0("problem_id_",i,".txt")
    write.table(x[i],file=filename,quote=FALSE,row.names=FALSE,col.names=FALSE)
  }
}
pml_write_files(pred_mod2)
```
